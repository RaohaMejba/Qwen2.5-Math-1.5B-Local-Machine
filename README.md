# Qwen2.5-Math-1.5B Local Inference

This project demonstrates how to run the [Qwen2.5-Math-1.5B](https://huggingface.co/Qwen/Qwen2.5-Math-1.5B) model locally for mathematical reasoning and language generation using Hugging Face Transformers.

---

## Requirements

- Python 3.8+
- PyTorch (with GPU support for better performance)
- Transformers
- Accelerate (optional, for device mapping)

## Install dependencies:

```bash
pip install torch transformers accelerate

